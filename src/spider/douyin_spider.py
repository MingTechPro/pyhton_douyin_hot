"""
æŠ–éŸ³çˆ¬è™«å®ç°æ¨¡å—

@author: MingTechPro
@version: 1.0.0
@date: 2025-08-15
@description: è¯¥æ¨¡å—å®ç°äº†æŠ–éŸ³çƒ­æ¦œæ•°æ®çš„çˆ¬å–åŠŸèƒ½ï¼Œç»§æ‰¿è‡ªBaseSpideråŸºç±»ï¼Œ
             æä¾›äº†å®Œæ•´çš„æŠ–éŸ³çƒ­æ¦œæ•°æ®è·å–ã€è§£æå’Œå¤„ç†åŠŸèƒ½ã€‚

ä¸»è¦åŠŸèƒ½:
- æŠ–éŸ³çƒ­æ¦œæ•°æ®çˆ¬å–
- æ•°æ®è§£æå’Œæ ¼å¼åŒ–
- ç¼“å­˜æœºåˆ¶æ”¯æŒ
- é€Ÿç‡é™åˆ¶æ§åˆ¶
- é”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶

ä¾èµ–æ¨¡å—:
- base_spider: åŸºç¡€çˆ¬è™«ç±»
- constants: å¸¸é‡å®šä¹‰
- models: æ•°æ®æ¨¡å‹
- config_manager: é…ç½®ç®¡ç†
- performance: æ€§èƒ½ç›‘æ§å·¥å…·
"""
import time
import json
import traceback
from typing import Optional, Dict, Any, List
from datetime import datetime

from .base_spider import BaseSpider
from ..core.constants import Constants
from ..core.models import HotListResponse, HotListItem, VideoArticle, CrawlResult
from ..config.config_manager import AppConfig
from ..utils.performance import CacheManager, RateLimiter


class DouyinSpider(BaseSpider):
    """
    æŠ–éŸ³çƒ­æ¦œçˆ¬è™«å®ç°ç±»
    
    ç»§æ‰¿è‡ªBaseSpideråŸºç±»ï¼Œä¸“é—¨ç”¨äºçˆ¬å–æŠ–éŸ³çƒ­æ¦œæ•°æ®ã€‚
    æ”¯æŒç¼“å­˜æœºåˆ¶ã€é€Ÿç‡é™åˆ¶ã€é”™è¯¯é‡è¯•ç­‰åŠŸèƒ½ã€‚
    
    @extends {BaseSpider} åŸºç¡€çˆ¬è™«ç±»
    @implements {crawl} çˆ¬å–æ–¹æ³•
    @implements {_fetch_hot_list_data} è·å–çƒ­æ¦œæ•°æ®
    @implements {_process_hot_list_item} å¤„ç†çƒ­æ¦œé¡¹ç›®
    @implements {_process_video_detail} æå–è§†é¢‘æ–‡ç« ä¿¡æ¯
    
    @example
        config = AppConfig()
        logger = LogManager.get_logger()
        cache_manager = CacheManager()
        rate_limiter = RateLimiter()
        
        spider = DouyinSpider(
            config=config,
            logger=logger,
            cache_manager=cache_manager,
            rate_limiter=rate_limiter
        )
        
        result = spider.crawl()
        if result.success:
            print(f"çˆ¬å–æˆåŠŸï¼Œè·å–åˆ° {len(result.data.items)} æ¡æ•°æ®")
    """
    
    def __init__(self, config: AppConfig, logger=None, cache_manager: Optional[CacheManager] = None, rate_limiter: Optional[RateLimiter] = None):
        """
        åˆå§‹åŒ–æŠ–éŸ³çˆ¬è™«å®ä¾‹
        
        åˆ›å»ºæŠ–éŸ³çˆ¬è™«å¯¹è±¡ï¼Œè®¾ç½®é…ç½®ã€æ—¥å¿—å™¨ã€ç¼“å­˜ç®¡ç†å™¨å’Œé€Ÿç‡é™åˆ¶å™¨ã€‚
        
        @param {AppConfig} config - åº”ç”¨é…ç½®å¯¹è±¡ï¼ŒåŒ…å«çˆ¬è™«è¿è¡Œæ‰€éœ€çš„æ‰€æœ‰é…ç½®å‚æ•°
        @param {object} logger - æ—¥å¿—å™¨å¯¹è±¡ï¼Œç”¨äºè®°å½•çˆ¬è™«è¿è¡Œæ—¥å¿—
        @param {CacheManager} cache_manager - ç¼“å­˜ç®¡ç†å™¨ï¼Œç”¨äºç¼“å­˜çˆ¬å–ç»“æœï¼Œé¿å…é‡å¤è¯·æ±‚
        @param {RateLimiter} rate_limiter - é€Ÿç‡é™åˆ¶å™¨ï¼Œç”¨äºæ§åˆ¶è¯·æ±‚é¢‘ç‡ï¼Œé¿å…è¢«åçˆ¬è™«æœºåˆ¶æ£€æµ‹
        
        @example
            config = AppConfig()
            logger = LogManager.get_logger()
            cache_manager = CacheManager(max_size=100, ttl=3600)
            rate_limiter = RateLimiter(max_requests=10, time_window=60)
            
            spider = DouyinSpider(
                config=config,
                logger=logger,
                cache_manager=cache_manager,
                rate_limiter=rate_limiter
            )
        """
        super().__init__(config, logger)
        self.cache_manager = cache_manager
        self.rate_limiter = rate_limiter
        
    def crawl(self) -> CrawlResult:
        """
        æ‰§è¡Œçˆ¬å–æ“ä½œ
        
        ä¸»è¦çš„çˆ¬å–æ–¹æ³•ï¼Œè´Ÿè´£ï¼š
        - æ£€æŸ¥ç¼“å­˜ä¸­æ˜¯å¦æœ‰å¯ç”¨æ•°æ®
        - ä½¿ç”¨æµè§ˆå™¨è·å–æŠ–éŸ³çƒ­æ¦œæ•°æ®
        - è§£æå’Œæ ¼å¼åŒ–æ•°æ®
        - å¤„ç†çƒ­æ¦œé¡¹ç›®
        - è¿”å›çˆ¬å–ç»“æœ
        
        @returns {CrawlResult} çˆ¬å–ç»“æœå¯¹è±¡ï¼ŒåŒ…å«æˆåŠŸçŠ¶æ€ã€æ•°æ®ã€æ‰§è¡Œæ—¶é—´ç­‰ä¿¡æ¯
        
        @throws {Exception} å½“çˆ¬å–è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯æ—¶æŠ›å‡º
        
        @example
            result = spider.crawl()
            if result.success:
                print(f"çˆ¬å–æˆåŠŸï¼Œå¤„ç†äº† {result.items_processed} æ¡æ•°æ®")
            else:
                print(f"çˆ¬å–å¤±è´¥: {result.error_message}")
        """
        start_time = time.time()
        items_processed = 0
        items_success = 0
        
        try:
            # æ£€æŸ¥ç¼“å­˜ä¸­æ˜¯å¦æœ‰å¯ç”¨æ•°æ®
            if self.cache_manager and self.config.enable_cache:
                cache_key = f"hot_list_{datetime.now().strftime('%Y%m%d_%H')}_{self.config.max_items}"
                cached_data = self.cache_manager.get(cache_key)
                if cached_data:
                    self.logger.info(f"ğŸ’¾ ä½¿ç”¨ç¼“å­˜æ•°æ®")
                    return CrawlResult(
                        success=True,
                        data=cached_data,
                        execution_time=time.time() - start_time,
                        items_processed=len(cached_data.items),
                        items_success=len(cached_data.items)
                    )
            
            # ä½¿ç”¨æµè§ˆå™¨è·å–æ•°æ®
            with self.get_browser() as browser:
                # è·å–çƒ­æ¦œæ•°æ®
                hot_list_json = self._fetch_hot_list_data(browser)
                if not hot_list_json:
                    return CrawlResult(
                        success=False,
                        error_message="è·å–çƒ­æ¦œæ•°æ®å¤±è´¥",
                        execution_time=time.time() - start_time
                    )
                
                # æå–çƒ­æ¦œæ•°æ®
                hot_list_data = hot_list_json.get(Constants.DATA_FIELD)
                if not hot_list_data:
                    return CrawlResult(
                        success=False,
                        error_message=f"çƒ­æ¦œæ•°æ®æ ¼å¼å¼‚å¸¸ï¼šç¼ºå°‘{Constants.DATA_FIELD}å­—æ®µ",
                        execution_time=time.time() - start_time
                    )
                
                # åˆ›å»ºå“åº”å¯¹è±¡
                hot_list_response = HotListResponse(
                    fetch_time=datetime.now()
                )
                
                # å¤„ç†çƒ­æ¦œé¡¹ç›®
                hot_items_list = hot_list_data.get(Constants.WORD_LIST_FIELD, [])
                if not hot_items_list:
                    return CrawlResult(
                        success=False,
                        error_message="çƒ­æ¦œæ•°æ®ä¸ºç©º",
                        execution_time=time.time() - start_time
                    )
                
                # æ ¹æ®é…ç½®å†³å®šæ˜¯å¦è·³è¿‡ç¬¬ä¸€æ¡ï¼ˆç½®é¡¶ï¼‰æ•°æ®
                if self.config.skip_top_item and len(hot_items_list) > 1:
                    hot_items_list = hot_items_list[1:]
                    self.logger.info("â­ï¸  è·³è¿‡ç½®é¡¶æ•°æ®")
                
                # å¤„ç†æ¯ä¸ªçƒ­æ¦œé¡¹ç›®
                for i, hot_item_data in enumerate(hot_items_list):
                    # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°æœ€å¤§é¡¹ç›®æ•°é™åˆ¶
                    if i >= self.config.max_items:
                        break
                    
                    items_processed += 1
                    
                    try:
                        # å¤„ç†å•ä¸ªçƒ­æ¦œé¡¹ç›®
                        hot_item = self._process_hot_list_item(hot_item_data, browser)
                        if hot_item:
                            hot_list_response.items.append(hot_item)
                            items_success += 1
                            self.logger.info(f"âœ… [{i+1}] {hot_item.title}")
                        else:
                            self.logger.warning(f"âŒ [{i+1}] å¤„ç†å¤±è´¥")
                    except Exception as e:
                        self.logger.error(f"âŒ [{i+1}] å¤„ç†å‡ºé”™: {str(e)}")
                        continue
                    
                    # è¯·æ±‚é—´éš”æ§åˆ¶
                    if i < len(hot_items_list) - 1 and self.config.request_interval > 0:
                        time.sleep(self.config.request_interval)
                
                # ç¼“å­˜ç»“æœ
                if self.cache_manager and self.config.enable_cache:
                    cache_key = f"hot_list_{datetime.now().strftime('%Y%m%d_%H')}_{self.config.max_items}"
                    self.cache_manager.set(cache_key, hot_list_response)
                    self.logger.info("ğŸ’¾ æ•°æ®å·²ç¼“å­˜")
                
                return CrawlResult(
                    success=True,
                    data=hot_list_response,
                    execution_time=time.time() - start_time,
                    items_processed=items_processed,
                    items_success=items_success
                )
                
        except Exception as e:
            self.logger.error(f"âŒ çˆ¬å–è¿‡ç¨‹å‡ºé”™: {str(e)}")
            if self.config.debug:
                self.logger.error(f"ğŸ” é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
            return CrawlResult(
                success=False,
                error_message=str(e),
                execution_time=time.time() - start_time,
                items_processed=items_processed,
                items_success=items_success
            )
    
    def _fetch_hot_list_data(self, browser) -> Optional[Dict[str, Any]]:
        """
        è·å–çƒ­æ¦œæ•°æ®
        Args:
            browser: æµè§ˆå™¨å®ä¾‹
        Returns:
            Dict[str, Any]: çƒ­æ¦œæ•°æ®
        """
        @self.retry_on_failure(
            max_retries=self.config.hot_list_max_retries,
            delay=self.config.hot_list_delay
        )
        def _fetch():
            request_start = time.time()
            try:
                browser.listen.start(Constants.API_SEARCH_LIST)
                browser.get(self.config.hot_list_url)
                response = browser.listen.wait(timeout=self.config.hot_list_timeout)
                
                if response is None:
                    raise Exception("æœªæ”¶åˆ°å“åº”æ•°æ®")
                    
                data = response.response.body
                if data is None:
                    raise Exception("å“åº”ä½“ä¸ºç©º")
                    
                request_duration = time.time() - request_start
                self.logger.info(f"âœ… çƒ­æ¦œæ•°æ®è·å–æˆåŠŸ ({request_duration:.2f}ç§’)")
                
                # è®°å½•è¯·æ±‚ç»Ÿè®¡
                self.record_request(True, request_duration)
                
                return data
            except Exception as e:
                request_duration = time.time() - request_start
                self.logger.error(f"âŒ è·å–çƒ­æ¦œæ•°æ®å¤±è´¥ ({request_duration:.2f}ç§’): {str(e)}")
                self.record_request(False, request_duration)
                raise
        
        return _fetch()
    
    def _fetch_video_detail(self, browser, url: str) -> Optional[Dict[str, Any]]:
        """
        è·å–è§†é¢‘è¯¦æƒ…æ•°æ®
        Args:
            browser: æµè§ˆå™¨å®ä¾‹
            url: è§†é¢‘URL
        Returns:
            Dict[str, Any]: è§†é¢‘è¯¦æƒ…æ•°æ®
        """
        @self.retry_on_failure(
            max_retries=self.config.video_detail_max_retries,
            delay=self.config.video_detail_delay
        )
        def _fetch():
            request_start = time.time()
            try:
                # ç®€åŒ–è§†é¢‘è¯¦æƒ…è·å–æ—¥å¿—
                browser.listen.start(Constants.API_AWEME_DETAIL)
                browser.get(url)
                response = browser.listen.wait(timeout=self.config.video_detail_timeout)
                
                if response is None:
                    self.logger.warning("è·å–è§†é¢‘è¯¦æƒ…è¶…æ—¶")
                    request_duration = time.time() - request_start
                    self.record_request(False, request_duration)
                    return None
                    
                data = response.response.body
                if data is None:
                    self.logger.warning("è§†é¢‘è¯¦æƒ…å“åº”ä½“ä¸ºç©º")
                    request_duration = time.time() - request_start
                    self.record_request(False, request_duration)
                    return None
                    
                request_duration = time.time() - request_start
                # è®°å½•æˆåŠŸè¯·æ±‚
                self.record_request(True, request_duration)
                return data
            except Exception as e:
                request_duration = time.time() - request_start
                self.logger.error(f"âŒ è·å–è§†é¢‘è¯¦æƒ…å¤±è´¥: {str(e)}")
                self.record_request(False, request_duration)
                return None
        
        return _fetch()
    
    def _process_hot_list_item(self, item_data: Dict[str, Any], browser) -> Optional[HotListItem]:
        """
        å¤„ç†çƒ­æ¦œé¡¹ç›®
        Args:
            item_data: çƒ­æ¦œé¡¹ç›®æ•°æ®
            browser: æµè§ˆå™¨å®ä¾‹
        Returns:
            HotListItem: å¤„ç†åçš„çƒ­æ¦œé¡¹ç›®
        """
        try:
            # éªŒè¯æ•°æ®å®Œæ•´æ€§
            if not self._validate_hot_list_item(item_data):
                self.logger.warning("çƒ­æ¦œé¡¹ç›®æ•°æ®éªŒè¯å¤±è´¥ï¼Œè·³è¿‡...")
                return None
            
            # æå–åŸºæœ¬ä¿¡æ¯
            item_id = item_data.get(Constants.SENTENCE_ID_FIELD)
            item_title = self.clean_text(item_data.get(Constants.WORD_FIELD))
            item_position = int(item_data.get(Constants.POSITION_FIELD))
            item_popularity = int(item_data.get(Constants.HOT_VALUE_FIELD))
            item_views = int(item_data.get(Constants.VIEW_COUNT_FIELD))
            
            # æ„å»ºURL - ä½¿ç”¨åŠ å¯†æ¨¡å¼é˜²æ­¢æµè§ˆå™¨è§£æé—®é¢˜
            from ..utils.formatters import create_encrypted_url
            if self.config.url_encoding_enabled:
                item_url = create_encrypted_url(
                    base_url=self.config.hot_list_url,
                    item_id=item_id,
                    title=item_title,
                    encryption_method=self.config.url_encoding_method
                )
            else:
                # å¦‚æœç¦ç”¨URLç¼–ç ï¼Œä½¿ç”¨åŸå§‹æ–¹å¼ï¼ˆä¸æ¨èï¼‰
                item_url = f"{self.config.hot_list_url}/{item_id}/{item_title}"
            
            # è®°å½•è°ƒè¯•ä¿¡æ¯
            self.logger.debug(f"ä½ç½®ï¼š{item_position}, çƒ­åº¦ï¼š{item_popularity}, æµè§ˆé‡ï¼š{item_views}")
            
            # åˆ›å»ºçƒ­æ¦œé¡¹ç›®
            hot_list_item = HotListItem(
                position=item_position,
                title=item_title,
                url=item_url,
                popularity=item_popularity,
                views=item_views,
                created_at=datetime.now()
            )
            
            # è·å–è§†é¢‘è¯¦æƒ…
            video_detail_json = self._fetch_video_detail(browser, item_url)
            
            if video_detail_json is not None:
                # å¤„ç†è§†é¢‘è¯¦æƒ…æ•°æ®
                video_article = self._process_video_detail(video_detail_json)
                if video_article:
                    hot_list_item.articles.append(video_article)
            
            return hot_list_item
            
        except Exception as e:
            self.logger.error(f"å¤„ç†çƒ­æ¦œé¡¹ç›®æ—¶å‘ç”Ÿå¼‚å¸¸ï¼š{str(e)}")
            return None
    
    def _process_video_detail(self, video_detail_json: Dict[str, Any]) -> Optional[VideoArticle]:
        """
        å¤„ç†è§†é¢‘è¯¦æƒ…æ•°æ®
        Args:
            video_detail_json: è§†é¢‘è¯¦æƒ…JSONæ•°æ®
        Returns:
            VideoArticle: è§†é¢‘æ–‡ç« å¯¹è±¡
        """
        try:
            # å¤„ç†è¿”å›æ•°æ®æ ¼å¼é—®é¢˜
            if isinstance(video_detail_json, str):
                if not video_detail_json.strip():
                    return None
                try:
                    video_detail_json = json.loads(video_detail_json)
                except json.JSONDecodeError:
                    return None
            
            # æ£€æŸ¥å¹¶æå–è§†é¢‘è¯¦æƒ…æ•°æ®
            video_detail_data = video_detail_json.get(Constants.AWEME_DETAIL_FIELD)
            if not video_detail_data:
                return None
            
            # éªŒè¯è§†é¢‘æ•°æ®
            if not self._validate_video_data(video_detail_data):
                return None
            
            # æå–è§†é¢‘ä¿¡æ¯
            video_id = str(video_detail_data.get(Constants.AWEME_ID_FIELD)).strip()
            video_title = self.clean_text(video_detail_data.get(Constants.DESC_FIELD, ""))
            
            if not video_id:
                return None
            
            video_short_url = f"{self.config.video_url}/{video_id}"
            
            # å®‰å…¨åœ°è·å–è§†é¢‘URL
            raw_video_url = self.safe_get_nested_value(
                video_detail_data, 
                [Constants.VIDEO_FIELD, Constants.BIT_RATE_FIELD, 0, Constants.PLAY_ADDR_FIELD, Constants.URL_LIST_FIELD, 0],
                ""
            )
            
            # æ¸…æ´—è§†é¢‘URL
            video_play_url = self.sanitize_url(raw_video_url) if raw_video_url else ""
            
            # åˆ›å»ºè§†é¢‘æ–‡ç« å¯¹è±¡
            return VideoArticle(
                title=video_title,
                short_url=video_short_url,
                video_url=video_play_url,
                created_at=datetime.now()
            )
            
        except Exception as e:
            self.logger.error(f"å¤„ç†è§†é¢‘è¯¦æƒ…æ—¶å‘ç”Ÿå¼‚å¸¸ï¼š{str(e)}")
            return None
    
    def _validate_hot_list_item(self, item: Dict[str, Any]) -> bool:
        """
        éªŒè¯çƒ­æ¦œé¡¹ç›®æ•°æ®å®Œæ•´æ€§
        Args:
            item: çƒ­æ¦œé¡¹ç›®æ•°æ®
        Returns:
            bool: æ•°æ®æ˜¯å¦æœ‰æ•ˆ
        """
        required_fields = [
            Constants.SENTENCE_ID_FIELD,
            Constants.WORD_FIELD,
            Constants.POSITION_FIELD,
            Constants.HOT_VALUE_FIELD,
            Constants.VIEW_COUNT_FIELD
        ]
        
        for field in required_fields:
            if field not in item or item[field] is None:
                return False
        
        # éªŒè¯æ•°æ®ç±»å‹
        try:
            position = int(item[Constants.POSITION_FIELD])
            hot_value = int(item[Constants.HOT_VALUE_FIELD])
            view_count = int(item[Constants.VIEW_COUNT_FIELD])
            
            if position <= 0 or hot_value < 0 or view_count < 0:
                return False
                
        except (ValueError, TypeError):
            return False
        
        # éªŒè¯æ ‡é¢˜é•¿åº¦
        title = str(item[Constants.WORD_FIELD]).strip()
        if len(title) == 0 or len(title) > 200:
            return False
            
        return True
    
    def _validate_video_data(self, video_data: Dict[str, Any]) -> bool:
        """
        éªŒè¯è§†é¢‘æ•°æ®å®Œæ•´æ€§
        Args:
            video_data: è§†é¢‘æ•°æ®
        Returns:
            bool: æ•°æ®æ˜¯å¦æœ‰æ•ˆ
        """
        if not isinstance(video_data, dict):
            return False
            
        # æ£€æŸ¥å¿…è¦å­—æ®µ
        if Constants.AWEME_ID_FIELD not in video_data:
            return False
            
        aweme_id = video_data.get(Constants.AWEME_ID_FIELD)
        if not aweme_id or not str(aweme_id).strip():
            return False
            
        return True
