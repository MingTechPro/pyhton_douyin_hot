"""
æ—¥å¿—æ¸…ç†å·¥å…·æ¨¡å—

@author: MingTechPro
@version: 1.0.0
@date: 2025-08-15
@description: è¯¥æ¨¡å—æä¾›äº†æ—¥å¿—æ–‡ä»¶æ¸…ç†åŠŸèƒ½ï¼Œå¯ä»¥æ‰‹åŠ¨æ¸…ç†æ—§çš„æ—¥å¿—æ–‡ä»¶ï¼Œ
             é‡Šæ”¾ç£ç›˜ç©ºé—´ï¼Œä¿æŒæ—¥å¿—ç›®å½•çš„æ•´æ´ã€‚

ä¸»è¦åŠŸèƒ½:
- æ¸…ç†æŒ‡å®šå¤©æ•°ä¹‹å‰çš„æ—¥å¿—æ–‡ä»¶
- æŒ‰æ–‡ä»¶å¤§å°æ¸…ç†æ—¥å¿—æ–‡ä»¶
- ç»Ÿè®¡æ—¥å¿—æ–‡ä»¶ä¿¡æ¯
- å®‰å…¨çš„æ—¥å¿—æ¸…ç†æ“ä½œ

@example
    # æ¸…ç†7å¤©å‰çš„æ—¥å¿—æ–‡ä»¶
    from src.utils.log_cleaner import LogCleaner
    cleaner = LogCleaner("logs")
    cleaner.cleanup_by_age(days=7)
    
    # æ¸…ç†è¶…è¿‡100MBçš„æ—¥å¿—æ–‡ä»¶
    cleaner.cleanup_by_size(max_size_mb=100)
    
    # è·å–æ—¥å¿—æ–‡ä»¶ç»Ÿè®¡ä¿¡æ¯
    stats = cleaner.get_log_stats()
    print(f"æ€»æ–‡ä»¶æ•°: {stats['total_files']}, æ€»å¤§å°: {stats['total_size_mb']:.2f}MB")
"""

import os
import glob
from pathlib import Path
from datetime import datetime, timedelta
from typing import Dict, List, Tuple
import logging


class LogCleaner:
    """
    æ—¥å¿—æ¸…ç†å™¨ç±»
    
    æä¾›å¤šç§æ—¥å¿—æ¸…ç†ç­–ç•¥ï¼ŒåŒ…æ‹¬æŒ‰æ—¶é—´ã€æŒ‰å¤§å°ç­‰ã€‚
    æ”¯æŒå®‰å…¨çš„æ¸…ç†æ“ä½œï¼Œé¿å…è¯¯åˆ é‡è¦æ–‡ä»¶ã€‚
    
    @author: MingTechPro
    @version: 1.0.0
    @date: 2025-08-15
    
    ä¸»è¦ç‰¹æ€§:
    - æŒ‰æ—¶é—´æ¸…ç†æ—§æ—¥å¿—æ–‡ä»¶
    - æŒ‰å¤§å°æ¸…ç†æ—¥å¿—æ–‡ä»¶
    - ç»Ÿè®¡æ—¥å¿—æ–‡ä»¶ä¿¡æ¯
    - å®‰å…¨çš„æ¸…ç†æ“ä½œ
    - è¯¦ç»†çš„æ¸…ç†æŠ¥å‘Š
    
    @example
        cleaner = LogCleaner("logs")
        
        # æ¸…ç†7å¤©å‰çš„æ—¥å¿—
        result = cleaner.cleanup_by_age(days=7)
        print(f"æ¸…ç†äº† {result['deleted_count']} ä¸ªæ–‡ä»¶")
        
        # è·å–ç»Ÿè®¡ä¿¡æ¯
        stats = cleaner.get_log_stats()
        print(f"å‰©ä½™æ–‡ä»¶: {stats['total_files']} ä¸ª")
    """
    
    def __init__(self, log_dir: str = "logs"):
        """
        åˆå§‹åŒ–æ—¥å¿—æ¸…ç†å™¨
        
        @param {str} log_dir - æ—¥å¿—ç›®å½•è·¯å¾„
        """
        self.log_dir = Path(log_dir)
        self.logger = logging.getLogger(__name__)
        
        # ç¡®ä¿æ—¥å¿—ç›®å½•å­˜åœ¨
        self.log_dir.mkdir(parents=True, exist_ok=True)
    
    def get_log_files(self, pattern: str = "spider_*.log") -> List[Path]:
        """
        è·å–æ—¥å¿—æ–‡ä»¶åˆ—è¡¨
        
        @param {str} pattern - æ–‡ä»¶åŒ¹é…æ¨¡å¼
        @returns {List[Path]} æ—¥å¿—æ–‡ä»¶è·¯å¾„åˆ—è¡¨
        
        @example
            files = cleaner.get_log_files("spider_*.log")
            print(f"æ‰¾åˆ° {len(files)} ä¸ªæ—¥å¿—æ–‡ä»¶")
        """
        pattern_path = self.log_dir / pattern
        return [Path(f) for f in glob.glob(str(pattern_path)) if Path(f).is_file()]
    
    def get_log_stats(self) -> Dict:
        """
        è·å–æ—¥å¿—æ–‡ä»¶ç»Ÿè®¡ä¿¡æ¯
        
        @returns {Dict} ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        
        @example
            stats = cleaner.get_log_stats()
            print(f"æ€»æ–‡ä»¶æ•°: {stats['total_files']}")
            print(f"æ€»å¤§å°: {stats['total_size_mb']:.2f}MB")
        """
        files = self.get_log_files()
        total_size = sum(f.stat().st_size for f in files)
        
        # æŒ‰æ—¶é—´åˆ†ç»„ç»Ÿè®¡
        now = datetime.now()
        today_files = []
        week_files = []
        month_files = []
        older_files = []
        
        for file in files:
            file_mtime = datetime.fromtimestamp(file.stat().st_mtime)
            age_days = (now - file_mtime).days
            
            if age_days == 0:
                today_files.append(file)
            elif age_days <= 7:
                week_files.append(file)
            elif age_days <= 30:
                month_files.append(file)
            else:
                older_files.append(file)
        
        return {
            "total_files": len(files),
            "total_size_mb": total_size / (1024 * 1024),
            "today_files": len(today_files),
            "week_files": len(week_files),
            "month_files": len(month_files),
            "older_files": len(older_files),
            "files": files
        }
    
    def cleanup_by_age(self, days: int = 7, dry_run: bool = False) -> Dict:
        """
        æŒ‰æ—¶é—´æ¸…ç†æ—¥å¿—æ–‡ä»¶
        
        @param {int} days - ä¿ç•™å¤©æ•°
        @param {bool} dry_run - è¯•è¿è¡Œæ¨¡å¼ï¼Œä¸å®é™…åˆ é™¤æ–‡ä»¶
        @returns {Dict} æ¸…ç†ç»“æœ
        
        @example
            # è¯•è¿è¡Œï¼ŒæŸ¥çœ‹ä¼šåˆ é™¤å“ªäº›æ–‡ä»¶
            result = cleaner.cleanup_by_age(days=7, dry_run=True)
            print(f"å°†åˆ é™¤ {result['to_delete_count']} ä¸ªæ–‡ä»¶")
            
            # å®é™…æ‰§è¡Œæ¸…ç†
            result = cleaner.cleanup_by_age(days=7, dry_run=False)
            print(f"å·²åˆ é™¤ {result['deleted_count']} ä¸ªæ–‡ä»¶")
        """
        cutoff_time = datetime.now() - timedelta(days=days)
        files = self.get_log_files()
        
        to_delete = []
        for file in files:
            file_mtime = datetime.fromtimestamp(file.stat().st_mtime)
            if file_mtime < cutoff_time:
                to_delete.append(file)
        
        deleted_count = 0
        deleted_files = []
        errors = []
        
        if not dry_run:
            for file in to_delete:
                try:
                    file.unlink()
                    deleted_count += 1
                    deleted_files.append(str(file))
                    self.logger.info(f"å·²åˆ é™¤æ—§æ—¥å¿—æ–‡ä»¶: {file}")
                except Exception as e:
                    error_msg = f"åˆ é™¤æ–‡ä»¶å¤±è´¥: {file}, é”™è¯¯: {e}"
                    errors.append(error_msg)
                    self.logger.error(error_msg)
        
        return {
            "to_delete_count": len(to_delete),
            "deleted_count": deleted_count,
            "deleted_files": deleted_files,
            "errors": errors,
            "cutoff_time": cutoff_time,
            "dry_run": dry_run
        }
    
    def cleanup_by_size(self, max_size_mb: float = 100, dry_run: bool = False) -> Dict:
        """
        æŒ‰å¤§å°æ¸…ç†æ—¥å¿—æ–‡ä»¶
        
        @param {float} max_size_mb - æœ€å¤§æ€»å¤§å°(MB)
        @param {bool} dry_run - è¯•è¿è¡Œæ¨¡å¼
        @returns {Dict} æ¸…ç†ç»“æœ
        
        @example
            # æ¸…ç†è¶…è¿‡100MBçš„æ—¥å¿—æ–‡ä»¶
            result = cleaner.cleanup_by_size(max_size_mb=100)
            print(f"å·²åˆ é™¤ {result['deleted_count']} ä¸ªæ–‡ä»¶")
        """
        files = self.get_log_files()
        
        # æŒ‰ä¿®æ”¹æ—¶é—´æ’åºï¼Œä¼˜å…ˆåˆ é™¤æ—§æ–‡ä»¶
        files.sort(key=lambda f: f.stat().st_mtime)
        
        total_size = sum(f.stat().st_size for f in files)
        max_size_bytes = max_size_mb * 1024 * 1024
        
        to_delete = []
        current_size = total_size
        
        for file in files:
            if current_size <= max_size_bytes:
                break
            
            file_size = file.stat().st_size
            to_delete.append(file)
            current_size -= file_size
        
        deleted_count = 0
        deleted_files = []
        errors = []
        
        if not dry_run:
            for file in to_delete:
                try:
                    file.unlink()
                    deleted_count += 1
                    deleted_files.append(str(file))
                    self.logger.info(f"å·²åˆ é™¤å¤§æ—¥å¿—æ–‡ä»¶: {file}")
                except Exception as e:
                    error_msg = f"åˆ é™¤æ–‡ä»¶å¤±è´¥: {file}, é”™è¯¯: {e}"
                    errors.append(error_msg)
                    self.logger.error(error_msg)
        
        return {
            "original_size_mb": total_size / (1024 * 1024),
            "target_size_mb": max_size_mb,
            "to_delete_count": len(to_delete),
            "deleted_count": deleted_count,
            "deleted_files": deleted_files,
            "errors": errors,
            "dry_run": dry_run
        }
    
    def cleanup_duplicates(self, dry_run: bool = False) -> Dict:
        """
        æ¸…ç†é‡å¤çš„æ—¥å¿—æ–‡ä»¶ï¼ˆåŸºäºæ–‡ä»¶åæ¨¡å¼ï¼‰
        
        @param {bool} dry_run - è¯•è¿è¡Œæ¨¡å¼
        @returns {Dict} æ¸…ç†ç»“æœ
        
        @example
            # æ¸…ç†é‡å¤çš„æ—¥å¿—æ–‡ä»¶
            result = cleaner.cleanup_duplicates()
            print(f"å·²åˆ é™¤ {result['deleted_count']} ä¸ªé‡å¤æ–‡ä»¶")
        """
        files = self.get_log_files()
        
        # æŒ‰æ–‡ä»¶ååˆ†ç»„
        file_groups = {}
        for file in files:
            # æå–åŸºç¡€æ–‡ä»¶åï¼ˆå»æ‰æ—¶é—´æˆ³ï¼‰
            base_name = file.stem.split('_')[0]  # å–spideréƒ¨åˆ†
            if base_name not in file_groups:
                file_groups[base_name] = []
            file_groups[base_name].append(file)
        
        to_delete = []
        for base_name, group_files in file_groups.items():
            if len(group_files) > 1:
                # ä¿ç•™æœ€æ–°çš„æ–‡ä»¶ï¼Œåˆ é™¤å…¶ä»–æ–‡ä»¶
                group_files.sort(key=lambda f: f.stat().st_mtime, reverse=True)
                to_delete.extend(group_files[1:])  # åˆ é™¤é™¤æœ€æ–°æ–‡ä»¶å¤–çš„æ‰€æœ‰æ–‡ä»¶
        
        deleted_count = 0
        deleted_files = []
        errors = []
        
        if not dry_run:
            for file in to_delete:
                try:
                    file.unlink()
                    deleted_count += 1
                    deleted_files.append(str(file))
                    self.logger.info(f"å·²åˆ é™¤é‡å¤æ—¥å¿—æ–‡ä»¶: {file}")
                except Exception as e:
                    error_msg = f"åˆ é™¤æ–‡ä»¶å¤±è´¥: {file}, é”™è¯¯: {e}"
                    errors.append(error_msg)
                    self.logger.error(error_msg)
        
        return {
            "to_delete_count": len(to_delete),
            "deleted_count": deleted_count,
            "deleted_files": deleted_files,
            "errors": errors,
            "dry_run": dry_run
        }
    
    def print_stats(self) -> None:
        """
        æ‰“å°æ—¥å¿—æ–‡ä»¶ç»Ÿè®¡ä¿¡æ¯
        
        @returns {None}
        
        @example
            cleaner.print_stats()
            # è¾“å‡º: æ€»æ–‡ä»¶æ•°: 25, æ€»å¤§å°: 45.67MB
        """
        stats = self.get_log_stats()
        
        print(f"ğŸ“Š æ—¥å¿—æ–‡ä»¶ç»Ÿè®¡ä¿¡æ¯:")
        print(f"   æ€»æ–‡ä»¶æ•°: {stats['total_files']}")
        print(f"   æ€»å¤§å°: {stats['total_size_mb']:.2f}MB")
        print(f"   ä»Šæ—¥æ–‡ä»¶: {stats['today_files']}")
        print(f"   æœ¬å‘¨æ–‡ä»¶: {stats['week_files']}")
        print(f"   æœ¬æœˆæ–‡ä»¶: {stats['month_files']}")
        print(f"   æ›´æ—©æ–‡ä»¶: {stats['older_files']}")


def main():
    """
    å‘½ä»¤è¡Œå…¥å£å‡½æ•°
    
    æä¾›å‘½ä»¤è¡Œç•Œé¢æ¥ä½¿ç”¨æ—¥å¿—æ¸…ç†åŠŸèƒ½ã€‚
    
    @returns {None}
    """
    import argparse
    
    parser = argparse.ArgumentParser(description="æ—¥å¿—æ–‡ä»¶æ¸…ç†å·¥å…·")
    parser.add_argument("--log-dir", default="logs", help="æ—¥å¿—ç›®å½•è·¯å¾„")
    parser.add_argument("--days", type=int, default=7, help="ä¿ç•™å¤©æ•°")
    parser.add_argument("--max-size", type=float, help="æœ€å¤§æ€»å¤§å°(MB)")
    parser.add_argument("--duplicates", action="store_true", help="æ¸…ç†é‡å¤æ–‡ä»¶")
    parser.add_argument("--dry-run", action="store_true", help="è¯•è¿è¡Œæ¨¡å¼")
    parser.add_argument("--stats", action="store_true", help="æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯")
    
    args = parser.parse_args()
    
    cleaner = LogCleaner(args.log_dir)
    
    if args.stats:
        cleaner.print_stats()
        return
    
    if args.duplicates:
        result = cleaner.cleanup_duplicates(dry_run=args.dry_run)
        print(f"é‡å¤æ–‡ä»¶æ¸…ç†ç»“æœ: {result['deleted_count']} ä¸ªæ–‡ä»¶å·²åˆ é™¤")
        return
    
    if args.max_size:
        result = cleaner.cleanup_by_size(max_size_mb=args.max_size, dry_run=args.dry_run)
        print(f"å¤§å°æ¸…ç†ç»“æœ: {result['deleted_count']} ä¸ªæ–‡ä»¶å·²åˆ é™¤")
        return
    
    # é»˜è®¤æŒ‰æ—¶é—´æ¸…ç†
    result = cleaner.cleanup_by_age(days=args.days, dry_run=args.dry_run)
    print(f"æ—¶é—´æ¸…ç†ç»“æœ: {result['deleted_count']} ä¸ªæ–‡ä»¶å·²åˆ é™¤")


if __name__ == "__main__":
    main()
